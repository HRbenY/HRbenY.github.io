---
title: 总复习.baked
author: Spa-Master
date: '2026-01-13 14:21:51'
updated: '2026-01-13 14:21:51'
tags: []
---

## 考试范围


### 矩阵论

| PPT条目             | 考试状态       | 老师录音/PPT批注原话摘录                                |
| ----------------- | ---------- | --------------------------------------------- |
| **基底之间的变换**       | **✅ 划重点**  | “...它的一个基底、维数、坐标、基底之间的变换...这个一定要知道。”          |
| **线性变换的对角化**      | **✅ 划重点**  | “线性变换对应个矩阵，它是否可以对角化...寻找特征值或者特征向量。”           |
| **Jordan阵、最小多项式** | **✅ 划重点**  | “Jordan阵，最小多项式... 简单的计算我会考它。”                 |
| **UR分解、SVD分解**    | **✅ 划重点**  | “UR分解，SVD分解... 是必须要知道的。”                      |
| **三角分解、满秩分解**     | **⚠️ 可能考** | 录音中提到了一句“三角分解...”，虽然没说必考，但PPT上列出且未划掉，建议作为次重点。 |

---

### 数值分析

| PPT条目                     | 考试状态          | 老师录音/PPT批注原话摘录                                |
| ------------------------- | ------------- | --------------------------------------------- |
| **Gauss消元法、LU分解**         | **✅ 划重点**     | “线性方程组的解法... Gauss消元法，LU分解...” (录音提及保留)       |
| **Cholesky分解**            | **❌ 明确不考**    | “Cholesky分解... 画掉。” (PPT上打叉)                  |
| **Jacobi/Gauss-Seidel迭代** | **❌ 明确不考**    | “迭代法：Jacobi 迭代，Gauss-Seidel迭代... 画掉。”         |
| **Newton迭代法 (阶收敛)**       | **✅ 划重点**     | “非线性方程迭代求根... Newton迭代法... **必考**。”           |
| **Newton弦截法**             | **❌ 明确不考**    | “Newton弦截法... 画掉。”                            |
| **Hermite插值**             | **✅ 划重点**     | 属于插值法部分，PPT明确下划线，录音提及要看等距节点Newton插值。          |
| **带权内积、正交多项式**            | **⚠️ 重点但免公式** | PPT批注：“**公式不用记**”。录音：“公式不用记... 理解它的原理和计算方法。”  |
| **曲线拟合最小二乘法**             | **✅ 划重点**     | PPT批注：“**作业题例数 1, 2, 3**” (暗示考题与作业高度相关)。      |
| **梯形、Simpson公式**          | **✅ 划重点**     | PPT批注：“**复化公式 (要知道)**”。录音强调复化梯形/Simpson是重点。   |
| **Gauss求积公式**             | **⚠️ 可能考**    | PPT打星号，录音说：“Gauss求积公式... **可能考**。” (属于高风险考点)。 |
| **Euler法、改进Euler法**       | **✅ 划重点**     | PPT打钩。属于ODE数值解的基础。                            |
| **ODE单步法收敛与稳定性**          | **✅ 划重点**     | PPT下划线+星号。录音：“稳定性... 绝对稳定区域... **必须要知道**。”    |

*（复习Newton迭代法时，结合几何意义理解收敛性会更容易记忆，尤其是切线逼近的过程。）*
*（ODE稳定性部分，建议看一眼Euler法的“绝对稳定区域”图像，这通常是这部分考点的核心。）*
  
---

### 数理统计

| PPT条目                | 考试状态       | 老师录音/PPT批注原话摘录                    |
| -------------------- | ---------- | --------------------------------- |
| **矩估计、极大似然估计**       | **✅ 划重点**  | PPT未划掉，属于参数估计的核心方法。               |
| **Rao-Cramer定理、一致性** | **❌ 明确不考** | “Rao-Cramer定理，一致性... 画掉。” (PPT打叉) |
| **正态总体均值/方差区间估计**    | **✅ 划重点**  | PPT下划线+星号。录音提到：“单个正态总体的均值... 必考。” |
| **正态总体假设检验**         | **✅ 划重点**  | PPT下划线+星号。录音同上，强调假设检验与区间估计是联动的考点。 |

  ![](file:///C:%5CUsers%5C707%5Churun%5CSPA-Master's%20Vault%5C%E8%AF%BE%E7%A8%8B%5C%E5%BA%94%E7%94%A8%E9%AB%98%E7%AD%89%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%5Cattachments%5C%E8%80%83%E8%AF%95%E8%8C%83%E5%9B%B41.jpg)
  ![](file:///C:%5CUsers%5C707%5Churun%5CSPA-Master's%20Vault%5C%E8%AF%BE%E7%A8%8B%5C%E5%BA%94%E7%94%A8%E9%AB%98%E7%AD%89%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%5Cattachments%5C%E8%80%83%E8%AF%95%E8%8C%83%E5%9B%B42.jpg) 

## 矩阵论


## 基变换

$B_1$到$B_2$的基变换矩阵P:
$$
B_2 = B_1P
$$
## 维数公式

$$\dim(W_1 + W_2) = \dim(W_1) + \dim(W_2) - \dim(W_1 \cap W_2)$$
## 线性变化的基变换

假设$P$是$B_1$到$B_2$的过度矩阵，$B_2=B_1P$ ，$B_1$下的线性变换T的矩阵是$A$，那么T在$B_2$下的矩阵是
$$
B = P^{-1}AP
$$

本质上是两次坐标翻译的过程。假设我们有新基$B_2$的输入向量，要用T对他线性变换，而这个T只接收旧基$B_1$的输入，输出也是$B_1$的坐标。那么中间就需要两次坐标翻译。首先左乘P翻译成$B_1$下的坐标，输入T后再翻译回$B_2$。如下
$$\text{最终结果} = \underbrace{P^{-1}}_{\text{3.翻译出}} \cdot \underbrace{A}_{\text{2.处理}} \cdot \underbrace{P}_{\text{1.翻译进}} \cdot \text{输入向量}$$
## 基偶
我们需要按顺序把定义域（输入空间）的基向量代入 $T$ 中计算，然后把结果用值域（输出空间）的基向量表示出来。
线性变换在基偶{$\alpha_1,\alpha_2,\alpha_3$}与{$\beta_1,\beta_2,\beta_3$}下的矩阵，就是用第一组基作为输入，第二组基表示输出。
若 $𝑊1+𝑊2$中任一向量只能唯一地分解为 $𝑊1$中的一个向量与 $𝑊2$中的一个向量之和，则 $𝑊1+𝑊2$称为 $𝑊1,𝑊2$的直和,记为 $𝑊1⊕𝑊2$.

![](file:///C:%5CUsers%5C707%5Churun%5CSPA-Master's%20Vault%5C%E8%AF%BE%E7%A8%8B%5C%E5%BA%94%E7%94%A8%E9%AB%98%E7%AD%89%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%5Cattachments%5CPasted%20image%2020260111002037.png)
证明Rn是V1 V2 的直和，可以V1 V2无交集 + dimV1 + dimV2 = dimRn
这两个概念是线性代数中判断矩阵性质（尤其是能不能对角化）的**核心工具**。
### 1. 零化多项式—— “能打中靶子的子弹”

定义：

如果把矩阵 $A$ 代入一个多项式 $f(x)$，结果算出来是零矩阵（$f(A) = 0$），那么这个 $f(x)$ 就叫 $A$ 的零化多项式。

- **直观理解**：就是能“消灭”矩阵 $A$ 的多项式。
    
- **特点**：零化多项式有**无数个**。
    
    - 如果 $x^2 - 1$ 能消灭 $A$（即 $A^2 - I = 0$），那么 $(x^2 - 1)(x + 3)$ 肯定也能消灭 $A$，因为它包含了一个能让 $A$ 变成 0 的因子。
        

> 例子：
> 
>  $A^2 + A = 2I$，移项得 $A^2 + A - 2I = 0$。
> 
> 这说明 $f(x) = x^2 + x - 2$ 就是 $A$ 的一个零化多项式。

---

### 2. 最小多项式  —— “口径最小的子弹”

定义：

在所有能消灭 $A$ 的零化多项式里，次数最低且最高次项系数为 1 的那个多项式，叫最小多项式，通常记为 $m(\lambda)$ 或 $\mu_A(x)$。

- **直观理解**：它是零化多项式里的“老大”或者“基因”。
    
- **两个最关键的性质：**
    
    1. **整除性**：任何其他的零化多项式，一定能被最小多项式**整除**。
        
        - _也就是：如果 $f(A)=0$，那么 $m(x)$ 一定是 $f(x)$ 的因式。_
            
    2. **根的同源性**：最小多项式的根，和特征多项式的根**完全一样**（只是重数可能不同）。
        
        - _也就是：特征值是 $\lambda_1, \lambda_2$，那么最小多项式里一定有 $(x-\lambda_1)$ 和 $(x-\lambda_2)$。_
            

---

### 3. 为什么它们能判断“对角化”？（重中之重）

> 黄金定理：
> 
> 一个矩阵 $A$ 可对角化 $\iff$ 它的最小多项式没有重根（全是互不相同的单根）。

**例子：**

1. 已知 $f(x) = x^2 + x - 2 = (x-1)(x+2)$ 是 $A$ 的一个零化多项式。
    
2. **根据整除性**，最小多项式 $m(x)$ 必须是 $f(x)$ 的因子。
    
3. $f(x)$ 的因子只有几种可能：
    
    - $x-1$ （无重根）
        
    - $x+2$ （无重根）
        
    - $(x-1)(x+2)$ （无重根）
        
4. 不管 $m(x)$ 是哪一个，它都**没有重根**。
    
5. **结论**：所以 $A$ 一定可以对角化。
    

---

### 4. 举个栗子（彻底搞懂代数重数 vs 几何重数）

为了看清**最小多项式**和**特征多项式**的区别，我们要看两个长得很像但性质完全不同的矩阵：

矩阵 A（乖孩子，可对角化）：

$$A = \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix}$$

- **特征多项式**：$|\lambda I - A| = (\lambda - 2)^2$。（代数重数是2）
    
- 最小多项式：
    
    你会发现，只要一次方 $A - 2I$ 就已经是零矩阵了。
    
    所以 $m(x) = x - 2$。
    
- **判断**：$m(x)$ 是单根（一次方），所以**可对角化**。
    

矩阵 B（坏孩子，Jordan 块，不可对角化）：

$$B = \begin{pmatrix} 2 & 1 \\ 0 & 2 \end{pmatrix}$$

- **特征多项式**：$|\lambda I - B| = (\lambda - 2)^2$。（跟 A 一模一样！）
    
- 最小多项式：
    
    试一下一次方：$B - 2I = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \neq 0$。
    
    试一下两次方：$(B - 2I)^2 = 0$。
    
    所以 $m(x) = (x - 2)^2$。
    
- **判断**：$m(x)$ 有重根（二次方），所以**不可对角化**。
    

### 总结

- **零化多项式**：只要代入 $A$ 等于 0 的就是。
    
- **最小多项式**：次数最低的那个零化多项式。
    
- **判据**：盯着**最小多项式**看，只要它的因式里没有 $(x-\lambda)^2, (x-\lambda)^3$ 这种带方幂的项，矩阵就能对角化。

## 凯莱定理

![](file:///C:%5CUsers%5C707%5Churun%5CSPA-Master's%20Vault%5C%E8%AF%BE%E7%A8%8B%5C%E5%BA%94%E7%94%A8%E9%AB%98%E7%AD%89%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%5Cattachments%5CPasted%20image%2020260111143625.png)

题目大概长这样
![](file:///C:%5CUsers%5C707%5Churun%5CSPA-Master's%20Vault%5C%E8%AF%BE%E7%A8%8B%5C%E5%BA%94%E7%94%A8%E9%AB%98%E7%AD%89%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%5Cattachments%5CPasted%20image%2020260111144807.png)
通常解法是用g除A的特征多项式得到余式。即

$$
g(A) = f(A)q(A)+r(A)
$$
其中$q(A)$为商式。

不过我们可以用**待定系数法**设余式为$a\lambda^2 +b \lambda + c$ ，而且这里1是重根，我们尝试$(\lambda - 1)(\lambda - 3)$ ，即$(A - 1E)(A - 3E)$算出来还是0，说明$(A - 1E)(A - 3E)$才是最小多项式。那么余式最高就变成了一次项，可以设为$a\lambda+b$ 。分别代入$g(1)$$g(3)$就可以解出来了。
## Jordan块的数量

考虑特征值$\lambda$的
- 代数重数：$\lambda$的幂数，决定了Jordan矩阵中特征值的数量，也是Jordan矩阵的大小。
- 几何重数：等于$\lambda$的线性独立特征向量的数量。决定了Jordan矩阵中Jordan块的数量
注意重数都是针对某一个特征值的，一个矩阵中可能有多个特征值，由多个小Jordan矩阵组成。

**紧盯着最小多项式看最大块，盯着代数重数看总和，盯着几何重数看块数。**

## 求$𝑃^{−1}𝐴𝑃=𝐽_𝐴$.

正常算A的特征值和对应的特征向量。既然要Jordan化，那肯定是有重根的，而且几何重数小于代数重数。比如$\lambda_1$的特征向量是$a_1$ ，那么我们再解一次特征方程，这次令$A\lambda=a_1$ ,解出来得到广义特征向量$\lambda2$。也可以可以通过该方程验证是否正确。

$$A = \begin{pmatrix} 2 & 0 & 1 & 0 \\ 0 & 2 & 1 & 0 \\ 0 & 0 & 2 & 1 \\ 0 & 0 & 0 & 2 \end{pmatrix}$$

## 满秩分解

将原矩阵做行初等变换，化成行最简型。比如
$$A = \begin{pmatrix} 1 & 2 & 3 & 0 \\ 0 & 2 & 1 & -1 \\ 1 & 0 & 2 & 1 \end{pmatrix} \xrightarrow{\text{行变换}} G = \begin{pmatrix} 1 & 0 & 2 & 1 \\ 0 & 1 & \frac{1}{2} & -\frac{1}{2} \\0 & 0 & 0 & 0 \end{pmatrix}$$
化成行最简后，列之间的关系依旧保留，比如这里第三列可以由前两列表示为:

$$\begin{pmatrix} 2 \\ 0.5 \end{pmatrix} = 2 \times \begin{pmatrix} 1 \\ 0 \end{pmatrix}+ 0.5 \times \begin{pmatrix} 0 \\ 1 \end{pmatrix}$$
那么在原矩阵中也一定有这种关系。那么我们用原矩阵的前两列作为基，右乘G就可以得到原矩阵。即
$$A=FG$$

## QR分解

$$
A = QR
$$
其中Q是正交矩阵，R是上三角矩阵。

### Q

将A按列施密特正交化后单位化得到Q

### R
$$Q = (\varepsilon_1, \varepsilon_2, \varepsilon_3), \quad A = (\alpha_1, \alpha_2, \alpha_3)$$
$$R = \begin{pmatrix} \langle \varepsilon_1, \alpha_1 \rangle & \langle \varepsilon_1, \alpha_2 \rangle & \langle \varepsilon_1, \alpha_3 \rangle \\ 0 & \langle \varepsilon_2, \alpha_2 \rangle & \langle \varepsilon_2, \alpha_3 \rangle \\ 0 & 0 & \langle \varepsilon_3, \alpha_3 \rangle \end{pmatrix}$$


因为Q是单位正交矩阵，满足$QQ^T=I$，所以可以如下计算R：
$$
R=Q^TA
$$

## 奇异值分解

$$A = U \Sigma V^T$$
假设$$A = \begin{pmatrix} 1 & 1 \\ 1 & 1 \\ 1 & -1 \end{pmatrix}$$
### $\Sigma$ 

奇异值，$A^TA$的特征值开方。

> 为什么不直接算A的特征值？
>
>因为A可能不是方阵，不存在特征值。$A^TA$是方阵，一定有特征值。且其特征值是A的奇异值的平方。

计算
$$
A^T A = \begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & -1 \end{pmatrix} \begin{pmatrix} 1 & 1 \\ 1 & 1 \\ 1 & -1 \end{pmatrix} = \begin{pmatrix} 3 & 1 \\ 1 & 3 \end{pmatrix}
$$
特征值为
- $\lambda_1 = 4$
- $\lambda_2 = 2$
奇异值为
- $\sigma_1 = \sqrt{4} = \mathbf{2}$
- $\sigma_2 = \sqrt{2} = \mathbf{\sqrt{2}}$

## $V$
V的每一列都是$A^TA$单位正交的特征向量。刚好可以跟$\Sigma$一起算。对应特征值的特征向量：

- 对于 $\lambda_1 = 4$：解 $(A^T A - 4I)x = 0$
    
    $\begin{pmatrix} -1 & 1 \\ 1 & -1 \end{pmatrix} \implies x_1 = x_2$。取单位向量：$\mathbf{v}_1 = \begin{pmatrix} \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} \end{pmatrix}$
    
- 对于 $\lambda_2 = 2$：解 $(A^T A - 2I)x = 0$
    
    $\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} \implies x_1 = -x_2$。取单位向量：$\mathbf{v}_2 = \begin{pmatrix} \frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}} \end{pmatrix}$
    

得到矩阵 $V$：

$$V = (\mathbf{v}_1, \mathbf{v}_2) = \begin{pmatrix} \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \end{pmatrix}$$
## U

利用刚才求出的矩阵V生成U
$$\mathbf{u}_i = \frac{1}{\sigma_i} A \mathbf{v}_i$$
其中$vi$是V的列向量，$\sigma_i$是对应的奇异值，$u_i$是U的列向量。注意顺序不要对应错了。

此外，**矩阵 $U$ 必须是 $m \times m$ 的方阵**（这题里是 $3 \times 3$），V只有两列，我们目前只得到了两个U的列向量。我们需要找一个向量，使得它 **同时垂直于** 已经算出来的 $u_1$ 和 $u_2$，并且长度为 1。

- 计算 $u_1$：

$$\mathbf{u}_1 = \frac{1}{2} \begin{pmatrix} 1 & 1 \\ 1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix} \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} \end{pmatrix} = \frac{1}{2} \begin{pmatrix} \sqrt{2} \\ \sqrt{2} \\ 0 \end{pmatrix} = \begin{pmatrix} \frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} \\ 0 \end{pmatrix}$$

- 计算 $u_2$：

$$\mathbf{u}_2 = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & 1 \\ 1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix} \frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}} \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} 0 \\ 0 \\ \frac{2}{\sqrt{2}} \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}$$

- 解方程组 $\begin{cases} u_1^T x = 0 \\ u_2^T x = 0 \end{cases}$，其实就是求零空间。 把 $u_1^T, u_2^T$ 作为行向量写成矩阵，求基础解系。
---
## 题外话

在$U$和$V$都是**单位正交矩阵**的情况下($U^T = U^{-1}$)

$$\begin{align}
A^T A &= (U \Sigma V^T)^T (U \Sigma V^T) \\
      &= (V \Sigma^T U^T) (U \Sigma V^T) \\
      &= V (\Sigma^T \Sigma) V^T \\
	  &= V (\Sigma^2) V^T = V (\Sigma^2) V^{-1}
\end{align}$$
得出来的$A^T A = V \Sigma^2 V^{-1}$就是特征值分解的形式。
- 中间的 **$\Sigma^2$**： $A^T A$ 的 **特征值矩阵**。
- 两边的 **$V$**： $A^T A$ 的 **特征向量矩阵**。

我们知道 SVD 的核心定义是 $A = U \Sigma V^T$，这意味着：

$$A V = U \Sigma$$

把列向量拆开看，就是：

$$A \mathbf{v}_i = \sigma_i \mathbf{u}_i$$

于是得到求解 $u_i$ 的黄金公式：

$$\boxed{\mathbf{u}_i = \frac{1}{\sigma_i} A \mathbf{v}_i}$$

## 数值分析


## 条件数

条件数描述一个矩阵的病态程度，计算方式是矩阵范数与逆矩阵范数之积。

$$
cond_1(A) = \|A\|_1 \cdot \|A^{-1}\|_1
$$
条件数的下标对应范数是几范数。条件数越高，说明矩阵越不稳定。于是引出相对误差分析。


## 相对误差

如果矩阵的系数受到扰动，不再是精确值。比如b受到扰动变成$\hat{b}$ ，绝对误差为$\|\delta b\|$ ，相对误差为$\frac{\|\delta b\|}{\|b\|}$  ，则解的相对误差为

    $$ \underbrace{\frac{\|\delta x\|}{\|x\|}}_{\text{解的相对误差}} \le \text{cond}(A) \cdot \underbrace{\frac{\|\delta b\|}{\|b\|}}_{\text{输入的相对误差}}$$

注意：

- 估计出来的解的相对误差是一个最大值，称误差限
- 乘条件数的是输入的相对误差而不是绝对误差


假设我们要解这个方程组：

$$\begin{cases} 5x - y = 7 \\ x + 5y = 17 \end{cases}$$

我们可以把它改写成“用其他变量表示当前变量”的形式：

- 由第1式算出 $x$：$x = \frac{7 + y}{5}$
    
- 由第2式算出 $y$：$y = \frac{17 - x}{5}$
    

这两种方法的区别就在于 **“什么时候用新算出来的值”**。
## Jacobi

### 策略：所有更新同步进行（旧的不去，新的不来）。

在计算第 $k+1$ 轮的 $x$ 和 $y$ 时，我们**只许**使用第 $k$ 轮（即上一轮）的旧值。哪怕你刚刚算出了新的 $x$，在计算这一轮的 $y$ 时也不能用，必须等下一轮。
### 迭代矩阵

对于线性方程组 $Ax=b$，我们将矩阵 $A$ 拆分为三部分：

$$A = D - L - U$$

- $D$：对角线矩阵（Diagonal）
    
- $L$：下三角矩阵的相反数（Lower）
    
- $U$：上三角矩阵的相反数（Upper）
    

我们将迭代公式写成通用的矩阵形式：

$$x^{(k+1)} = B x^{(k)} + f$$

这里的 $B$ 就是迭代矩阵。
其实也就是按策略更新后的矩阵。注意是方阵。
**Jacobi 的迭代矩阵**：$B_J = D^{-1}(L+U)$
## Gauss-Seidel

### 策略：一旦有新值，立刻使用（现炒现卖）。

在计算过程中，如果你已经算出了新的 $x$，那么在接着算 $y$ 的时候，**立刻**就用这个新的 $x$。
### 迭代矩阵

**Gauss-Seidel 的迭代矩阵**：$B_{GS} = (D-L)^{-1}U$
其实就是按策略更新后的矩阵。
## 收敛性
### 1. 充要条件


- **判据：** 计算迭代矩阵 $B$ 的谱半径 $\rho(B)$（即**特征值模的最大值**）。
    
- **结论：**
    
    - 若 $\rho(B) < 1$，则**收敛**。
        
    - 若 $\rho(B) \ge 1$，则**发散**。
        
    - $\rho(B)$ 越小，收敛速度越快。


### 2. 充分条件

**严格对角占优**：- 矩阵对角线上的那个数（绝对值），必须比这一行其他所有数的绝对值加起来还要大。

## 不动点迭代

反复计算$x_{n + 1} = \phi(x_n)$，尝试找到一个收敛点$x^*$，这个$x^*$就是不动点。

## 牛顿迭代

我们在函数的某一点A$(x_n, f(x_n))$处，要迭代出下一个点，我们期望这个点距离零点更近。

牛顿迭代法使用点A处的切线的过零点的横坐标作为$x_{n + 1}$，并重复这个过程。用公式描述：
$$
(x_{n + 1} - x_n) \cdot f'(x_n) + f(x_n) = 0
$$
整理得
$$
\boxed{x_{n + 1} = x_{n} - \frac{f(x_n)}{f'(x_n)}}
$$
### 收敛性

令$$\varphi(x) = x - \frac{f(x)}{f'(x)}$$
判断迭代法是否收敛，看导数的绝对值是否小于一就好。
我们要判断它是几阶，就是求 $\varphi'(x)$ 在真解 $x^*$ 处的值。

> 对于迭代过程 $x_{n+1} = \varphi(x_n)$，如果迭代函数 $\varphi(x)$ 在不动点 $x^*$ 处满足以下条件：$$\varphi'(x^*) = \varphi''(x^*) = \dots = \varphi^{(p-1)}(x^*) = 0$$且$$\varphi^{(p)}(x^*) \neq 0$$那么，该迭代法在 $x^*$ 附近是 **$p$ 阶收敛**的。

**第一步：求导**

利用除法求导法则：
$$\begin{aligned} \varphi'(x) &= 1 - \left( \frac{f(x)}{f'(x)} \right)' \\ &= 1 - \frac{f'(x) \cdot f'(x) - f(x) \cdot f''(x)}{[f'(x)]^2} \\ &= 1 - \frac{[f'(x)]^2 - f(x)f''(x)}{[f'(x)]^2} \\ &= \frac{f(x)f''(x)}{[f'(x)]^2} \end{aligned}$$

第二步：代入真解 $x^*$

因为 $x^*$ 是方程的根，所以 $f(x^*) = 0$。

代入上面的式子：

$$\varphi'(x^*) = \frac{0 \cdot f''(x^*)}{[f'(x^*)]^2} = 0$$

结论：

因为一阶导数 $\varphi'(x^*) = 0$，所以牛顿法起步就是二阶收敛（除非根是重根，导致分母也为0，那是特殊情况）。

下面讨论重根的情况。

### 有重根的收敛性

| **情况**   | **根的重数**       | **牛顿迭代公式**                               | **收敛阶数**             | **收敛因子**          |
| -------- | -------------- | ---------------------------------------- | -------------------- | ----------------- |
| **普通情况** | 单根 ($m=1$)     | $x_{n+1} = x_n - \frac{f}{f'}$           | **二阶 (Quadratic)**   | 0                 |
| **退化情况** | $m$ 重根 ($m>1$) | $x_{n+1} = x_n - \frac{f}{f'}$           | **降为一阶 (Linear)**    | $1 - \frac{1}{m}$ |
| **修正后**  | $m$ 重根 ($m>1$) | $x_{n+1} = x_n - \mathbf{m}\frac{f}{f'}$ | **恢复二阶 (Quadratic)** | 0                 |

####  如何判断/证明收敛阶数？（两种方法）

题目：已知 $x^*$ 是 $f(x)=0$ 的 $m$ 重根，判断牛顿迭代 $x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$ 的收敛性。

#### 方法 1：泰勒展开法 (适合 $m$ 未知)

**思路**：利用 $f(x)$ 在 $x^*$ 处前 $m-1$ 阶导数全为 0 的性质，只保留主项。

1. 展开 $f(x)$：
    
    $f(x) \approx \frac{f^{(m)}(x^*)}{m!} (x-x^*)^m$
    
2. 展开 $f'(x)$：
    
    $f'(x) \approx \frac{f^{(m)}(x^*)}{(m-1)!} (x-x^*)^{m-1}$
    
3. **计算比值**（这是最关键的一步，系数来源于阶乘的性质）：
    
    $$\frac{f(x)}{f'(x)} \approx \frac{ \frac{1}{m!} (x-x^*)^m }{ \frac{1}{(m-1)!} (x-x^*)^{m-1} } = \frac{(m-1)!}{m!} (x-x^*) = \mathbf{\frac{1}{m}}(x-x^*)$$
    
4. **代入迭代误差公式**：
    
    $$x_{n+1} - x^* = (x_n - x^*) - \frac{f(x_n)}{f'(x_n)} \approx (x_n - x^*) - \frac{1}{m}(x_n - x^*) = \left(1 - \frac{1}{m}\right)e_n$$
    
5. **结论**：误差 $e_{n+1} \approx (1 - \frac{1}{m})e_n$，故为**线性收敛**。
    

#### 方法 2：辅助函数法 (直观快速，适合 $m$ 已知具体数值时)

**思路**：把导致 0 的坏因子 $(x-x^*)^m$ 提出来，剩下的设为 $h(x)$。

1. **设** $f(x) = (x-x^*)^m h(x)$，其中 $h(x^*) \neq 0$。
    
2. **求导** $f'(x) = (x-x^*)^{m-1} [ m h(x) + (x-x^*)h'(x) ]$。
    
3. **代入比值**（约掉 $(x-x^*)^{m-1}$）：
    
    $$\frac{f(x)}{f'(x)} = \frac{(x-x^*)^m h(x)}{(x-x^*)^{m-1} [ m h(x) + \dots ]} = \frac{(x-x^*) h(x)}{m h(x) + \dots}$$
    
4. **取极限**（当 $x \to x^*$）：
    
    $$\frac{f(x)}{f'(x)} \approx \frac{h(x^*)}{m h(x^*)} (x-x^*) = \mathbf{\frac{1}{m}}(x-x^*)$$
    
5. **结论**：同上，误差系数为 $1 - \frac{1}{m}$，线性收敛。
    

---

### 三、 如何恢复为二阶收敛？

原理：

既然我们算出来，标准的牛顿步长 $\frac{f}{f'}$ 比实际需要的步长 $(x-x^*)$ 缩水了 $m$ 倍（只走了 $1/m$ 的路程）。

那么，我们在公式里人为地乘以 $m$，不就刚好抵消了吗？

**修正公式 (Modified Newton's Method)：**

$$\boxed{x_{n+1} = x_n - m \frac{f(x_n)}{f'(x_n)}}$$

简单的验证（必背）：

如果用修正公式，那么：

$$\begin{aligned} x_{n+1} - x^* &= (x_n - x^*) - m \cdot \frac{f(x_n)}{f'(x_n)} \\ &\approx (x_n - x^*) - m \cdot \left[ \frac{1}{m}(x_n - x^*) \right] \\ &= (x_n - x^*) - (x_n - x^*) \\ &= 0 \end{aligned}$$

一次迭代误差直接归零（在保留一阶主项的近似下），这说明误差的高阶项至少是二次方，也就是恢复了**二阶收敛**。

---

### 总结

1. **“重根”** $\rightarrow$ 牛顿法降级了，变成线性了。
    
2. **问“收敛阶是多少”** $\rightarrow$ 算出 $1 - 1/m$ 不等于 0，所以是 1 阶。
    
3. **问“怎么加速”** $\rightarrow$ 系数乘上重数 $m$。
    
4. **问“$m$ 未知怎么办？”** $\rightarrow$ 构造新函数 $\mu(x) = \frac{f(x)}{f'(x)}$，对 $\mu(x)$ 做牛顿法。因为 $f(x)$ 的 $m$ 重根永远是 $\mu(x)$ 的单根。



## Lagrange

### 基函数

这个基函数 $l_i(x)$ 只有两个核心任务（**也就是它的“0-1性质”）：

1. **在自己的节点（$x_i$）必须是 1**：当 $x$ 等于这个节点 $x_i$ 时，函数值为 1。
    
2. **在其他节点（$x_j, j \neq i$）必须是 0**：当 $x$ 等于其他任何节点时，函数值统统为 0。

公式为
$$l_i(x) = \prod_{j=0, j \neq i}^{n} \frac{x - x_j}{x_i - x_j}$$

> 假设有三个点 $x_0, x_1, x_2$。我们要写出 $l_1(x)$（中间那个点的基函数）：
> 
> $$l_1(x) = \frac{(x - x_0)}{(x_1 - x_0)} \cdot \frac{(x - x_2)}{(x_1 - x_2)}$$
>代入 $x_0$：分子第一项是 0 $\rightarrow$ 结果为 0。
>代入 $x_2$：分子第二项是 0 $\rightarrow$ 结果为 0。
>代入 $x_1$：分子变成 $(x_1-x_0)(x_1-x_2)$，和分母一样 $\rightarrow$ 结果为 1。
### Lagrange插值多项式

把每个点的**高度（$y$值）** 乘上它对应的**基函数** ，然后加起来：
$$L(x) = \sum_{i=0}^n f(x_i)l_i(x) = y_0 \cdot l_0(x) + y_1 \cdot l_1(x) + \dots + y_n \cdot l_n(x)$$
可以从$L(x)$的形式看出$f(x)$究竟是什么

### 误差余项

$$R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{i=0}^n (x - x_i)$$

$\prod_{i=0}^n (x - x_i)$保证插值节点上误差为0。

> 当将拉格朗日插值的节点逐渐逼近到同一点$x_0$的时候，$\prod_{i=0}^n (x - x_i)$就变成了泰勒公式里面的$(x-x_0)^{n+1}$

**注意**求导系数和阶乘次数都为$n + 1$。

一般会利用余项公式求插值多项式在某区间上的插值误差。此时要求的是误差上界，$\xi$ 取使 $|f^{(n+1)}(\xi)|$最大的值。$\prod_{i=0}^n (x - x_i)$ 太复杂的话不用求，也直接摆出来就好。
### 差商

$$f[x_0, x_1, ..., x_n] = \frac{f^{(n)}(\xi)}{n!}$$

> 符号 **$f[x_0, x_1, x_2, x_3, x_4]$** 读作“$f$ 关于节点 $x_0, \dots, x_4$ 的四阶差商”

**定理：** 若 $f(x)$ 是一个 $n$ 次多项式，即 $f(x) = a_n x^n + a_{n-1} x^{n-1} + \dots + a_0$，那么它的 **$n$ 阶差商** 就是它的 **最高次项系数 $a_n$**。

原理是什么？（直观理解）

导数的规律：

- 对 $x^4$ 求 1 次导 $\rightarrow$ 变 $x^3$
    
- 对 $x^4$ 求 2 次导 $\rightarrow$ 变 $x^2$
    
- ...
    
- 对 $x^4$ 求 4 次导 $\rightarrow$ 变 常数
    

差商其实就是 离散版本的“导数”。

$$f[x_i, x_j] = \frac{f(x_i) - f(x_j)}{x_i - x_j} \approx f'(x)$$

当你对一个 4 次多项式做 4 阶差商时，就像对它求了 4 次导数一样（虽然数值上差一个阶乘倍数），它会把所有低次项（$x^3, x^2 \dots$）都“消灭”掉，只留下最高次项的信息，变成一个**恒定的常数**。

**如果不是多项式...**
 $\xi$ 有范围，如果消不掉会让求误差界限。取 $\xi$为区间内让导数绝对值最大的值。

## Newton

$$N(x) = c_0 + c_1(x-z_0) + c_2(x-z_0)(x-z_1)+ ...+c_n\prod_{i = 0}^{n}(x-z_i)$$

借助差商表计算。取对角线作为多项式系数$c_i$，越靠右系数越高。
比如下面这个例子：

|**i**|**xi​**|**f(xi​) (0阶)**|**1阶差商 f[⋅,⋅]**|**2阶差商 f[⋅,⋅,⋅]**|**3阶差商 f[⋅,⋅,⋅,⋅]**|
|---|---|---|---|---|---|
|**0**|**0**|**3** ($c_0$)||||
||||$\frac{3-3}{1-0} = \mathbf{0}$ ($c_1$)|||
|1|1|3||$\frac{1/2 - 0}{3/2 - 0} = \frac{1/2}{3/2} = \mathbf{\frac{1}{3}}$ ($c_2$)||
||||$\frac{13/4 - 3}{3/2 - 1} = \frac{1/4}{1/2} = \frac{1}{2}$||$\frac{-11/3 - 1/3}{2 - 0} = \frac{-4}{2} = \mathbf{-2}$ ($c_3$)|
|2|3/2|13/4||$\frac{-19/6 - 1/2}{2 - 1} = -\frac{22}{6} = -\frac{11}{3}$||
||||$\frac{5/3 - 13/4}{2 - 3/2} = \frac{20-39}{12} \times 2 = -\frac{19}{6}$|||
|3|2|5/3||||

## 分段线性插值

把曲线分成小段，在每段上做n=1的Lagrange插值。

### 误差余项
> 其实就是Lagrange误差余项取n=1的情况，再取x为区间中点以取得最大误差。

$$|R(x)| \le \frac{M_2}{8} h^2$$
- **$M_2$**：是 $|f''(x)|$ 的最大值。
    
- **$h$**：是步长（相邻节点之间的距离），这里 $h = 0.1$。
    
- **$1/8$ 怎么来的？**：这是 $(x-x_i)(x-x_{i+1})$ 在区间中点取到的最大值的绝对值 $\frac{h^2}{4}$，再除以公式里的 $2!$，所以是 $\frac{1}{8}$。
## Hermite

在Newton插值得基础上将导数也纳入计算差商。一般题目会给定某点的函数值和导数。

比如

| **zi​** | **f(zi​)**    | **一阶差商**                                 | **二阶差商**                                  | **三阶差商**                                 |
| ------- | ------------- | ---------------------------------------- | ----------------------------------------- | ---------------------------------------- |
| **0**   | **0** ($c_0$) |                                          |                                           |                                          |
|         |               | $\frac{1-0}{0.5-0} = \mathbf{2}$ ($c_1$) |                                           |                                          |
| 0.5     | 1             |                                          | $\frac{2-2}{0.5-0} = \mathbf{0}$ ($c_2$)  |                                          |
|         |               | **$f'(0.5) = 2$** (特殊规则!)                |                                           | $\frac{-4-0}{1-0} = \mathbf{-4}$ ($c_3$) |
| 0.5     | 1             |                                          | $\frac{0-2}{1-0.5} = \frac{-2}{0.5} = -4$ |                                          |
|         |               | $\frac{1-1}{1-0.5} = 0$                  |                                           |                                          |
| 1       | 1             |                                          |                                           |                                          |
这里已知$f'(0.5)$，所以多写一行(0.5, 1)，并直接写一阶差商为2。正常读对角线作为牛顿插值的系数。


> 离散情况将积分换成求和。

最佳平方逼近，本质上就是高维空间里的“垂直投影”。最佳平方逼近的过程就是要让误差**垂直于**$\{1, x, x^2\}$张成的空间的每一个基方向。
## 内积

在几何里，判断两个向量是否垂直，我们用点积（Dot Product）是否为 0。
在函数的世界里，内积就是点积的连续版本：

$$\langle f, g \rangle = \int_a^b f(x)g(x) dx$$

如果这个积分为 0，我们就说这两个函数“垂直”（正交）。
## 法方程（正规方程）

我们要找系数 $c_0, c_1, c_2$，让**误差 $R = f - (c_0 \cdot 1 + c_1 \cdot x + c_2 \cdot x^2)$ 垂直于所有的基 $\{1, x, x^2\}$**。

这意味着我们要列出三个垂直方程：

1. 误差 垂直于 $1$：$\langle R, 1 \rangle = 0$
    
2. 误差 垂直于 $x$：$\langle R, x \rangle = 0$
    
3. 误差 垂直于 $x^2$：$\langle R, x^2 \rangle = 0$

我们可以将第二个式子展开看一下：

$$\langle R, x \rangle = \langle f - (c_0 \cdot 1 + c_1 \cdot x + c_2 \cdot x^2), \quad x \rangle = 0$$
用内积的定义展开后可以发现本质上是几项的和做积分，显然满足结合律和分配律。
拆开：
$$\langle f, x \rangle - c_0\langle 1, x \rangle - c_1\langle x, x \rangle - c_2\langle x^2, x \rangle = 0$$
把带 $c$ 的项移到等号左边，把已知的 $f$ 留到右边：
$$c_0\langle 1, x \rangle + c_1\langle x, x \rangle + c_2\langle x^2, x \rangle = \langle f, x \rangle$$
这就构成法方程的一行。将所有方程组合起来，我们得到法方程：

$$\boxed{H\mathbf{c} = \mathbf{b}\rightarrow\begin{pmatrix} \langle 1, 1 \rangle & \langle 1, x \rangle & \langle 1, x^2 \rangle \\ \langle x, 1 \rangle & \langle x, x \rangle & \langle x, x^2 \rangle \\ \langle x^2, 1 \rangle & \langle x^2, x \rangle & \langle x^2, x^2 \rangle \end{pmatrix} \begin{pmatrix} c_0 \\ c_1 \\ c_2 \end{pmatrix} = \begin{pmatrix} \langle f, 1 \rangle \\ \langle f, x \rangle \\ \langle f, x^2 \rangle \end{pmatrix}}$$
 > 离散情况下的H实际上就是$A^TA$ 
 
 **左边矩阵 $H$ 的元素 $\langle x^i, x^j \rangle$：**

- **含义**：这是**坐标轴之间的夹角/相关性**。
    
- **解释**：我们在用 $\{1, x, x^2\}$ 建立坐标系。但是这三个基函数并不是互相垂直的（正交的）。比如 $x$ 和 $x^2$ 在 $[0, \pi]$ 上都主要是正的，它们有“重叠”。
    
- 矩阵里的 $\langle x, x^2 \rangle$ 就是在衡量：基函数 $x$ 和基函数 $x^2$ 有多相似。如果它们完全垂直（正交），这个矩阵就会变成对角矩阵（非对角线全是0），解起来就超级简单。但因为它们不正交，我们需要这个矩阵来修正这种“坐标轴倾斜”带来的扭曲。
    

 **右边向量 $\mathbf{b}$ 的元素 $\langle f, x^i \rangle$：**

- **含义**：这是**目标函数在各个轴上的投影分量**。
    
- **解释**：
    
    - $\langle f, 1 \rangle$：$f$ 包含多少“常数成分”（也就是平均高度）。
        
    - $\langle f, x \rangle$：$f$ 包含多少“线性成分”（趋势）。
        
    - $\langle f, x^2 \rangle$：$f$ 包含多少“弯曲成分”。
        
- 这就像我们在问：目标函数 $f$ 和 $x$ 这个形状有多像？越像，积分值越大，说明在这个方向上的分量应该越多。

> 有时候列式求的时候f中有$x^2$或者$x$，可以把这些先放一边，算出余下部分后将系数相加。
## Legendre多项式

**核心思想：Gram-Schmidt 正交化**

想象我们在 $L^2[-1, 1]$ 空间里（权函数 $w(x)=1$）。我们手里有一堆最原始的素材：$\{1, x, x^2, x^3, \dots\}$。

这些素材并不互相垂直（比如 $x^2$ 和 $1$ 就不垂直，因为 $\int x^2 \cdot 1 dx \neq 0$）。

我们要做的，就是像雕刻一样，拿原始素材，剔除掉之前已经造好的方向，剩下的就是新的正交多项式。

#### **推导过程：**

1. 造 $P_0(x)$：
    
    取第一个素材 $1$。直接令 $P_0(x) = 1$。
    
2. 造 $P_1(x)$：
    
    取素材 $x$。
    
    检查：$x$ 和 $1$ 垂直吗？
    
    $$\int_{-1}^1 x \cdot 1 dx = 0$$
    
    垂直！太好了，不用修整。
    
    令 $P_1(x) = x$。
    
3. 造 $P_2(x)$（关键来了！）：
    
    取素材 $x^2$。它和 $P_0=1$ 垂直吗？
    
    $$\int_{-1}^1 x^2 \cdot 1 dx = \frac{2}{3} \neq 0$$
    
    不垂直！ 说明 $x^2$ 里面含有 $P_0$ 的成分（杂质）。我们要把这部分投影减掉。
    
    $$P_2(x) = x^2 - \frac{\langle x^2, P_0 \rangle}{\langle P_0, P_0 \rangle} P_0$$
    
    - 分子：$\int_{-1}^1 x^2 dx = \frac{2}{3}$
        
    - 分母：$\int_{-1}^1 1^2 dx = 2$
        
    - 系数：$\frac{2/3}{2} = \frac{1}{3}$
        
    
    所以初步形状是：$x^2 - \frac{1}{3}$。
    
    标准化（Legendre 的规矩）：
    
    数学家规定，Legendre 多项式在 $x=1$ 处必须等于 1（$P_n(1)=1$）。
    
    现在的 $1^2 - 1/3 = 2/3$，为了变成 1，我们需要乘以 $\frac{3}{2}$。
    
    $$P_2(x) = \frac{3}{2}(x^2 - \frac{1}{3}) = \mathbf{\frac{1}{2}(3x^2 - 1)}$$
    
    (看！系数 3 和 1 就是这么凑积分凑出来的)
    

#### **作弊神器：罗德里格斯公式 (Rodrigues' Formula)**

如果每次都算积分太累了，后来人们发现了一个通项公式，可以直接“求导”生成它们：

$$P_n(x) = \frac{1}{2^n n!} \frac{d^n}{dx^n} [(x^2 - 1)^n]$$

你可以试着把 $n=2$ 代进去算算，算出来就是 $\frac{1}{2}(3x^2-1)$。

---

## 二、 Chebyshev 多项式

**核心思想：三角换元**

Chebyshev 多项式的推导非常巧妙，它根本没用积分，而是用了一个恒等式。

定义：令 $x = \cos \theta$，则 $T_n(x) = \cos(n\theta)$。

这看起来是三角函数，怎么变成多项式了呢？

利用三角函数的积化和差公式！

#### **推导过程（利用递推）：**

我们知道一个三角恒等式：

$$\cos(n+1)\theta + \cos(n-1)\theta = 2\cos\theta \cos(n\theta)$$

移项，把 $\cos(n+1)\theta$ 留在一边：

$$\cos(n+1)\theta = 2\cos\theta \cos(n\theta) - \cos(n-1)\theta$$

现在把 $x = \cos \theta$ 和 $T_n(x) = \cos(n\theta)$ 代回去：

$$T_{n+1}(x) = 2x T_n(x) - T_{n-1}(x)$$

这就是著名的**三项递推公式**！只要有了前两个，后面的都能生出来。

1. 造 $T_0(x)$：
    
    $n=0$ 时，$\cos(0) = 1$。
    
    $T_0(x) = 1$
    
2. 造 $T_1(x)$：
    
    $n=1$ 时，$\cos(\theta) = x$。
    
    $T_1(x) = x$
    
3. 造 $T_2(x)$（系数来了！）：
    
    套用公式：$T_2 = 2x T_1 - T_0$
    
    $$T_2(x) = 2x(x) - 1 = \mathbf{2x^2 - 1}$$
    
4. 造 $T_3(x)$：
    
    套用公式：$T_3 = 2x T_2 - T_1$
    
    $$T_3(x) = 2x(2x^2 - 1) - x = 4x^3 - 2x - x = \mathbf{4x^3 - 3x}$$
    

#### **系数的规律**

你看，Chebyshev 的系数全是整数，而且最高次项系数总是 $2^{n-1}$。


---

## 总结一下“系数的身世”

|**种类**|**系数来源**|**推导工具**|**直观理解**|
|---|---|---|---|
|**Legendre**|**凑积分**|Gram-Schmidt 正交化|为了让 $\int P_n P_m dx = 0$，硬把 $x^n$ 里重叠的旧成分减掉，剩下的系数就是结果。|
|**Chebyshev**|**三角倍角**|递推公式 $T_{n+1}=2xT_n - T_{n-1}$|本质上是 $\cos(n\theta)$ 的多项式展开。系数来自 $2\cos\theta$ 的不断乘积。|

所以，当你看到 Legendre 的系数 $\frac{5}{9}, \frac{8}{9}$ 这种奇怪的分数时，不要惊讶，那是积分积出来的。

而看到 Chebyshev 的系数全是整数时，也不要惊讶，那是三角公式推出来的。
$$\int_a^b f(x) dx \approx (b-a) \sum_{k=0}^n C_k^{(n)} f(x_k)$$
根据Cotes系数的不同有不同的公式。常用的是n=1梯形公式和n=2辛普森公式。
## 梯形公式

$$I \approx \frac{b-a}{2} [f(a) + f(b)]=\frac{h}{2} [f(a) + f(b)]$$
这里因为梯形公式将整个区间视为一步，所以$h=b-a$

### 复化

把曲边梯形切成**首位相接**的 $n$ 个小条，每个小条都用**直边梯形**来近似，然后面积求和。

- **步长**：$h = \frac{b-a}{n}$
    
- **节点**：$x_k = a + k \cdot h \quad (k=0, 1, \dots, n)$
    
- 公式：
    
    $$T_n = \frac{h}{2} \left[ f(x_0) + 2\sum_{k=1}^{n-1} f(x_k) + f(x_n) \right]$$
注意首尾两个点是一倍，中间是两倍

### 误差余项

复化梯形公式的误差截断项（Error Term）为：

$$|E_T| \approx \frac{b-a}{12} h^2 \cdot M_2$$

- **$b-a$**：积分区间长度 $= 2.2 - 1.0 = 1.2$。
    
- **$h$**：步长 $= 1.6 - 1.0 = 0.6$。
    
- **$M_2$**：是 $|f''(x)|$ 在区间 $[1.0, 2.2]$ 上的最大值。

## 辛普森公式
$$I \approx \frac{b-a}{6} [f(a) + 4f(\frac{a+b}{2}) + f(b)]=\frac{h}{3} [f(a) + 4f(\frac{a+b}{2}) + f(b)]$$
辛普森的区间内有两个步长，所以$h=\frac{b-a}{2}$
### 复化

把积分区间切成 $n$ 等分（**注意：$n$ 必须是偶数**），每两个小段凑成一组（3个点），上面覆盖一条**抛物线**来近似。

- **条件**：$n$ 必须为**偶数**（因为辛普森公式每次消耗2个区间段）。
    
- **步长**：$h = \frac{b-a}{n}$
    
- 公式：
    
    $$S_n = \frac{h}{3} \left[ f(x_0) + 4\sum_{k=1,3,5\dots}^{n-1} f(x_k) + 2\sum_{k=2,4,6\dots}^{n-2} f(x_k) + f(x_n) \right]$$
也就是141的系数往后重合，重合一次变成14241，两次变成1424241。

### 误差余项 

Simpson 公式的误差截断项为：

$$|E_S| \approx \frac{b-a}{180} h^4 \cdot M_4$$

- **系数**：注意分母变成了 **180**（比梯形公式小得多）。
    
- **$h^4$**：步长的 4 次方。
    
- **$M_4$**：是 $|f^{(4)}(x)|$ 在区间上的最大值。

### 1. 欧拉法 (Euler Method)

欧拉法通过当前点的切线斜率来预测下一点，是一阶数值方法。

**详细步骤：**

1. **计算斜率**：计算微分方程在当前点 $(x_n, y_n)$ 处的斜率 $k_1 = f(x_n, y_n)$。
    
2. 向前预测：沿着斜率方向向前走步长 $h$，直接估算下一点的 $y$ 值。
    
    $$y_{n+1} = y_n + h \cdot k_1$$
    
3. **更新坐标**：$x_{n+1} = x_n + h$。
    

---

### 2. 改进欧拉法 (Improved Euler Method)

改进欧拉法（又称 Heun 方法）采用**预测-校正**策略，利用“出发点”和“预测点”两处的斜率平均值来推算下一点，精度更高。

**详细步骤：**

1. **预测 (Predictor)**：
    
    - 首先计算当前点 $(x_n, y_n)$ 的斜率 $k_1 = f(x_n, y_n)$。
        
    - 用欧拉法向前预测一个“粗略值”（预测点）$\overline{y}_{n+1}$。
        
        $$\overline{y}_{n+1} = y_n + h \cdot k_1$$
        
2. **校正 (Corrector)**：
    
    - 计算预测点 $(x_{n+1}, \overline{y}_{n+1})$ 处的斜率 $k_2 = f(x_{n+1}, \overline{y}_{n+1})$。
        
    - 取 $k_1$ 和 $k_2$ 的平均斜率 $k_{avg} = \frac{1}{2}(k_1 + k_2)$。
        
    - 用平均斜率重新计算更精确的 $y_{n+1}$。
        
        $$y_{n+1} = y_n + h \cdot k_{avg}$$
        
3. **更新坐标**：$x_{n+1} = x_n + h$。
比较真解和数值解的误差级别。真解泰勒展开，数值解进行二元泰勒展开，比较多项式。
这里认为数值解的起点是精确的，计算的是截断误差。

考虑
$$y'(x)=f(x,y),\qquad y(a)=y_0$$
有方法
$$y_{n+1}=y_n+h\, f\!\left(x_n+\frac h2,\; y_n+\frac h2 f(x_n,y_n)\right).$$
### 真解

因为 $x_{n+1}=x_n+h$，泰勒：

$$y(x_n+h)=y(x_n)+h y'(x_n)+\frac{h^2}{2}y''(x_n)+O(h^3).$$
现在把$y''(x_n)$表达出来

$$y''=\frac{d}{dx}y'=\frac{d}{dx}f(x,y(x)).$$
$$\frac{d}{dx}f(x,y)=f_x(x,y)+f_y(x,y)\cdot \frac{dy}{dx}.$$

而$\frac{dy}{dx}=y'=f(x,y)$ 所以
$$y''=f_x+f_y\,f.$$
> 就是二阶全微分


真解展开为
$$y(x+h)=y+h f+\frac{h^2}{2}(f_x+f_y f)+O(h^3).$$
（这里$f,f_x,f_y$都在$(x_n,y(x_n))$处取值）

### 分析解

这一步展开的是“用真值走一步”的数值结果

我们要展开的是
$$\tilde y_{n+1}=y + h\, f\!\left(x+\frac h2,\; y+\frac h2 f(x,y)\right).$$
令
$$k_2:= f\!\left(x+\frac h2,\; y+\frac h2 f\right).$$
那么$\tilde y_{n+1}=y+h k_2$

接下来将$k_2$在点$(x,y)$附近做二元泰勒展开，公式是
$$f(x+\Delta x,\,y+\Delta y)=f(x,y)+f_x\,\Delta x+f_y\,\Delta y+O(\Delta x^2+\Delta y^2).$$
这里
$$\Delta x=\frac h2,\qquad \Delta y=\frac h2 f.$$
代入

$$k_2 = f + f_x\frac h2 + f_y\left(\frac h2 f\right)+O(h^2)
= f+\frac h2(f_x+f_y f)+O(h^2).$$
于是
$$\tilde y_{n+1}=y+h k_2
= y+h f+\frac{h^2}{2}(f_x+f_y f)+O(h^3).$$

**对比两种方法的差距，从$h^3$才开始，所以截断误差是三阶，整体误差是二阶。**

## 稳定性分析

对任意单步法 ($y_{n+1}=\Phi(x_n,y_n;h)$)，做绝对稳定性分析时：

1. 取测试方程（例如 $y'=\lambda y$ $(\lambda\in\mathbb C)$）或实数。
    
2. 代入题目给定的$y_{n+1}$的递推关系化简得到  
    $$y_{n+1}=R(\lambda h)\cdot y_n  $$
    
3. **绝对稳定域**定义为  
    $${z:\ |R(z)|<1},\quad z=\lambda h.  $$
    
4. 若题目给 ($\lambda$<0)，再把 ($z=\lambda h$) 解回 ($h$) 的范围。

将采样点的位置也视为参数进行待定系数法求解。这样可以得到2n个系数，可以令原积分在1~$x^{2n-1}$的次数上严格相等。

> ！如果不满足说明不是高斯求积公式

| **特性**           | **Legendre (勒让德)**                     | **Chebyshev (切比雪夫)**                                |
| ---------------- | -------------------------------------- | --------------------------------------------------- |
| **符号**           | $P_n(x)$                               | $T_n(x)$                                            |
| **权函数** $w(x)$   | $1$                                    | $\frac{1}{\sqrt{1-x^2}}$                            |
| **积分对象**         | $\int_{-1}^1 f(x) dx$                  | $\int_{-1}^1 \frac{f(x)}{\sqrt{1-x^2}} dx$          |
| **生成公式**         | $(n+1)P_{n+1} = (2n+1)xP_n - nP_{n-1}$ | $T_{n+1} = 2xT_n - T_{n-1}$                         |
| **前几项**          | $1, x, \frac{3x^2-1}{2}$               | $1, x, 2x^2-1, 4x^3-3x$                             |
| **节点 $x_k$ 的来源** | $P_n(x)$ 的零点                           | $T_n(x)$ 的零点 $\Rightarrow \cos(\frac{2k-1}{2n}\pi)$ |
| **系数 $A_k$ 的特征** | 需要单独计算或查表                              | **恒定相等**，均为 $\frac{\pi}{n}$                         |
|                  |                                        |                                                     |


> 跟Legendre多项式的联系：
> 高斯公式中选取的**采样点（节点）$x_k$**，恰好就是 **$n$ 次勒让德多项式 $P_n(x)$ 的 $n$ 个零点（根）**。
## 解题步骤

#### Step 1: 区间标准化 (Interval Transformation)

检查积分区间是否为 $[-1, 1]$。如果不是 $[a, b]$，必须先换元：

- **换元公式**：$x = \frac{b-a}{2}t + \frac{a+b}{2}$
    
- **微分项**：$dx = \frac{b-a}{2} dt$
    
- **新积分**：$\int_a^b f(x)dx = \frac{b-a}{2} \int_{-1}^1 f(\dots) dt$
    

#### Step 2: 识别权函数 (Identify Weight Function)

观察被积函数的形式：

- 如果包含 $\frac{1}{\sqrt{1-x^2}}$ $\Rightarrow$ **Gauss-Chebyshev**（把剩下的部分当作 $f(x)$）。
    
- 如果是普通函数 $\Rightarrow$ **Gauss-Legendre**（把整体当作 $f(x)$）。
    

#### Step 3: 确定节点与系数 (Find Nodes & Weights)

根据题目要求的点数 $n$：

- **Legendre**：通常背诵 $n=2$ 和 $n=3$ 的数据，或者题目会给。
    
- **Chebyshev**：现场计算节点 $x_k = \cos(\dots)$，系数直接写 $\frac{\pi}{n}$。
    

#### Step 4: 代入求和 (Summation)

$$I \approx \text{区间系数} \times \sum_{k=1}^n A_k f(x_k)$$

注意：如果是 Chebyshev，公式自带权函数，不要把 $\frac{1}{\sqrt{1-x^2}}$ 重复计算进 $f(x)$ 里。

---

## 考前必背要点

考试不一定会给公式表，这几个数据是必须烂熟于心的：

#### 1. Gauss-Legendre (勒让德) —— “硬算型”

- **多项式**：
    
    - $P_2(x) = \frac{1}{2}(3x^2 - 1)$
    - $P_3(x) = \frac{1}{2}(5x^3 - 3x)$
        
- **节点与系数 (必须背)**：
    
    - **2点 ($n=2$)**：
        
        - 节点：$\pm \frac{1}{\sqrt{3}} \approx \pm 0.57735$
            
        - 系数：$1, 1$
            
    - **3点 ($n=3$)**：
        
        - 节点：$-\sqrt{0.6}, \quad 0, \quad \sqrt{0.6}$ （即 $\pm \sqrt{3/5}$）
            
        - 系数：$\frac{5}{9}, \quad \frac{8}{9}, \quad \frac{5}{9}$
            

#### 2. Gauss-Chebyshev (切比雪夫) —— “技巧型”

- **多项式**：
    
    - $T_n(x) = \cos(n \arccos x)$
        
- **节点公式 (理解记忆)**：
    
    - $x_k = \cos\left( \frac{2k-1}{2n} \pi \right), \quad k=1, 2, \dots, n$
        
    - _记忆窍门：分子是奇数 $\pi$，分母是 $2n$。_
        
- **系数公式 (秒杀关键)**：
    
    - $A_k \equiv \frac{\pi}{n}$
        
    - _记忆窍门：不管节点在哪，系数全是一样的，且和为 $\pi$。_
        

---

## 易错点提醒 (Pitfalls)

1. **忘记换 $dx$**：做区间变换时，最后忘记乘上 $\frac{b-a}{2}$ 这个系数。
    
2. **Chebyshev 的 $f(x)$ 提取**：
    
    - 原积分 $\int \frac{g(t)}{\sqrt{1-t^2}} dt$。
        
    - 公式用的是 $\sum \frac{\pi}{n} g(t_k)$。
        
    - **错误做法**：把 $\frac{1}{\sqrt{1-t_k^2}}$ 也代进去算。
        
    - **正确做法**：权函数已经被公式“吸收”了，只算分子部分 $g(t)$。



##  数理统计

## 统计量


$X$为抽样结果
#### **(1) $\bar{X}$：样本均值 (Sample Mean)**

- **定义**：$\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$
    
- **含义**：它代表你抽取的一组样本数据的**平均值**。
    
- **作用**：它是总体均值（Expectation, $\mu$ 或 $\lambda$）的无偏估计量。通俗地说，它是用来猜测总体“中心”在哪里的。
    

#### **(2) $S^2$：样本方差 (Sample Variance)**

- 定义：通常在数理统计教材中，$S^2$ 特指修正样本方差（无偏方差）。
    
    $$S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2$$
    
- **注意**：它的分母是 **$n-1$**，而不是 $n$。
    
- **含义**：它用来衡量样本数据的**波动程度**（离散程度）。
    
- **作用**：它是总体方差（Variance, $\sigma^2$）的**无偏估计量**。之所以用 $n-1$，就是为了让它的期望值 $E(S^2)$ 恰好等于总体方差。
    

#### **(3) $\frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2$：二阶样本中心矩**

- **定义**：这是未经修正的样本方差。
    
- **注意**：它的分母是 **$n$**。
    
- **含义**：这也是一种衡量数据波动程度的统计量，通常在**最大似然估计**中出现。
    
- **与 $S^2$ 的区别**：它是有偏差的（Biased）。它计算出的波动性通常比真实的总体波动性略小一点点。

$$E(\bar{X})=E(X)$$
$$D(\bar{X}) = \frac{D(x)}{n}$$
$$E(S^2) = D(X)$$$$E\left(\frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2\right)=\frac{n-1}{n}D(X)$$注意第四个为二阶样本中心距期望，是有偏估计

### 概率密度函数和概率分布

连续型成为概率密度函数，离散型称为概率分布。

计算均值的思路都是某点的x乘某点的概率。概率密度是xp(x)积分，概率分布是xp(x)求和


### 协方差
计算两个变量 $U$ 和 $V$ 的协方差，标准公式是：
$$Cov(U, V) = E\Big[ (X - \mu_x)(Y - \mu_y) \Big] = E(UV) - E(U)E(V)$$
理解$E(UV) - E(U)E(V)$：
U和V同时发生的概率和两者不相关情况下理论的概率的差距。
## 概率分布
### 1. 泊松分布

若 $X \sim \pi(\lambda)$，则：

- **期望**：$E(X) = \lambda$
    
- **方差**：$D(X) = \lambda$
    
- **概率分布律**：$P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k=0,1,2,\dots$

### 2. 几何分布

$$P(X=k) = (1-p)^{k-1}p$$

- 期望：$\frac{1}{p}$
### 3. 01分布

$$
P(X=1)=p
$$
- 期望：p
- 方差：p(1-p)
### 4. 高斯分布
$$f(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$
当 **$\mu = 0$** 且 **$\sigma = 1$** 时，称为**标准正态分布**，通常记作 $Z \sim N(0, 1)$。公式简化为：
$$\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}$$
![](file:///C:%5CUsers%5C707%5Churun%5CSPA-Master's%20Vault%5C%E8%AF%BE%E7%A8%8B%5C%E5%BA%94%E7%94%A8%E9%AB%98%E7%AD%89%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%5Cattachments%5CPasted%20image%2020260110150357.png)

就是抽样结果$X \le x$ 的概率。  
这三个分布（$\chi^2$、t、F）被称为数理统计中的**“三大抽样分布”**。

它们都有一个共同的“妈妈”——**标准正态分布** $N(0,1)$。

要理解它们，不要死记公式，而是要记住它们的**“出身”**（定义）和**“用途”**。

---

### 1. 卡方分布 ($\chi^2$ Distribution) —— 衡量“波动的总量”

![chi-square distribution with different degrees of freedom的图片](https://encrypted-tbn0.gstatic.com/licensed-image?q=tbn:ANd9GcQlP90bbEXpboQy8MlSxKop09R7o3NYAYHbK1aFYMmpHeV0hItPxcJ7FGMJur3x3-nuMuZEAUfow0ICNWtsVH3g3fKVOqJd9UwhD9J46DQILIisJMI)


- 出身（定义）：
    
    假设你有 $n$ 个相互独立的**标准正态分布**变量 $Z_1, Z_2, \dots, Z_n$。
    
    把它们平方后加起来，这个和就服从自由度为 $n$ 的卡方分布：
    
    $$X = Z_1^2 + Z_2^2 + \dots + Z_n^2 \sim \chi^2(n)$$
    
- **直观理解**：
    
    - 因为是“平方和”，所以卡方分布的值**永远是非负的**（都在 0 右边）。
        
    - 它衡量的是一组数据的**“波动总能量”**。
        
    - 图像是**右偏**（不对称）的，但随着自由度 $n$ 增大，它会越来越像正态分布（中心极限定理）。
        
- **用途**：
    
    - **跟方差有关**：最经典的应用就是样本方差 $S^2$ 的分布与卡方有关（$\frac{(n-1)S^2}{\sigma^2} \sim \chi^2$）。
        
    - **拟合优度检验**：看观测值和理论值差多少（平方差）。
        
    - **列联表检验**：看两个分类变量是否独立。

- 性质
	- 1.设$\chi^2 \sim \chi^2(n)$ ,则$E(\chi^2) = n,\ D(\chi^2) = 2n$ 
	- 2. 设$\chi_1^2 \sim \chi^2(n), \chi_2^2 \sim \chi^2(n)$，且$\chi_1^2$与$\chi_1^2$相互独立，则$\chi_1^2 + \chi_2^2 \sim \chi^2(n_1+n_2)$ 
---

### 2. t 分布 (Student's t-Distribution) —— “胖尾巴”的正态分布

![t-distribution vs standard normal distribution的图片](https://encrypted-tbn3.gstatic.com/licensed-image?q=tbn:ANd9GcQmw-F9akxT-o2WTmXK5E3kZww7beeCBxGuzY4ChMkmiBnTSdGpiIsbA_QoOzPac8Djl03OL3VkNHWSlbseeXMTM9Suf6RPfMcePv-dKGwguWcvwCE)


- 出身（定义）：
    
    假设 $Z$ 是标准正态分布，$Y$ 是卡方分布，且它俩独立。
    
    那么，$Z$ 除以 $\sqrt{Y/n}$ 就服从 t 分布：
    
    $$T = \frac{Z}{\sqrt{Y/n}} \sim t(n)$$
    
- **直观理解**：
    
    - 长得非常像标准正态分布（钟形，对称，中心在0）。
        
    - **区别**：t 分布的**尾巴更厚（Fatter Tails）**，峰更低。
        
    - **为什么？** 因为正态分布假设我们知道真实的方差 $\sigma^2$。但现实中我们不知道，只能用样本方差 $S^2$ 去估计。这个“估计”引入了额外的不确定性，所以导致两端的极端概率变大了（尾巴胖了）。
        
    - 当样本量 $n \to \infty$ 时，t 分布就变成了正态分布。
        
- **用途**：
    
    - **小样本均值检验**：当你不知道总体方差，且样本量较小（比如 $n<30$）时，用来检验均值（t-test）。
        

---

### 3. F 分布 (F-Distribution) —— 两个方差的“比值”

- 出身（定义）：
    
    假设有两个**独立**的卡方分布 $U \sim \chi^2(n_1)$ 和 $V \sim \chi^2(n_2)$。
    
    它们分别除以自己的自由度，然后相除：
    
    $$F = \frac{U/n_1}{V/n_2} \sim F(n_1, n_2)$$
    
- **直观理解**：
    
    - 因为卡方代表“方差/能量”，所以 F 分布本质上是**“方差的比值”**。
        
    - 既然是比值，且卡方非负，所以 F 分布也**永远非负**。
        
    - 图像也是**右偏**的。
        
- **用途**：
    
    - **方差分析 (ANOVA)**：这是 F 分布最著名的用途。比较多组数据的方差，看它们之间是否有显著差异（本质是在比较“组间差异”和“组内差异”的比值）。
        
    - **比较两个总体的方差**：检验两个总体波动是否一致。
        

---

### 一张图搞懂家族关系

为了方便记忆，你可以把它们看作**积木**：

1. **正态分布 ($Z$)**：最基础的积木。
    
2. **卡方分布 ($\chi^2$)**：把 $n$ 个正态积木**平方**后粘在一起。
    
3. **t 分布 ($t$)**：上面放一个正态积木，下面放一个“卡方积木的平方根”。
    
4. **F 分布 ($F$)**：上面放一个卡方积木，下面也放一个卡方积木（算比值）。
    

**它们之间还有一个著名的数学关系（考试常考）：**

- 如果你把 t 分布的变量平方，它就变成了 F 分布！
    
    $$T \sim t(n) \implies T^2 \sim F(1, n)$$
    
    (理解：分子是 $Z^2$ 也就是 $\chi^2(1)$，分母是 $\chi^2(n)/n$，这不就是 F 分布定义吗？)
## 矩估计

**核心思想**：让“理论上的平均值”等于“样本实际算出来的平均值”。 **$E(X) = \bar{X}$**

## 最大似然估计

**核心思想**：既然这些样本 $(x_1, x_2, \dots, x_n)$ 已经发生了，那么参数 $p$ 应该是多少，才使得**这一组数据出现的概率最大**？

在数学上，我们不想一个个猜，而是用**求导**来直接算极值点。

假设样本为 $x_1, x_2, \dots, x_n$，待求参数为 $\theta$。

### Step 1: 写出似然函数 $L(\theta)$

似然函数 $L(\theta)$ 就是“所有样本同时发生”的联合概率。因为样本独立，所以直接连乘：

$$L(\theta) = \prod_{i=1}^n P(x_i; \theta)$$
	注意，如果是连续型分布，这里的P直接换成概率密度函数f就可以了
### Step 2: 取对数 $\ln L(\theta)$ (最关键的一步)

为什么要取对数？

- $L(\theta)$ 是连乘 $\prod$，求导非常极其痛苦（乘法法则会死人的）。
    
- 取对数后，连乘变连加：$\ln(A \cdot B) = \ln A + \ln B$。
    
- 而且 $\ln x$ 是单调递增函数，$\ln L$ 最大的地方，$L$ 也最大，不影响结果。
    
    $$\ln L(\theta) = \sum_{i=1}^n \ln P(x_i; \theta)$$
    

### Step 3: 求导并令导数为 0

这是微积分找极值点的基本操作。

$$\frac{d}{d\theta} (\ln L(\theta)) = 0$$

### Step 4: 解方程

解出来的 $\theta$ 就是我们要的估计值 $\hat{\theta}$。

要说明一个估计量比另一个更“有效”，通常需要两个步骤：

1. **验证无偏性**：证明两个估计量都是$\sigma^2$的无偏估计（即它们的期望都等于$\sigma^2$）。
    
2. **比较方差**：计算两个估计量的方差，方差**更小**的那个就是更“有效”的。

## 常用性质

### 1. 期望 $E(\cdot)$ 的性质

期望就是“平均值”，它很听话，符号可以直接拆开。

- **常数提出去**：$E(cX) = cE(X)$
    
- **加法拆开**：$E(X + Y) = E(X) + E(Y)$ （**永远成立**，不管独不独立）
    
- **求和拆开**：$E(\sum_{i=1}^n X_i) = \sum_{i=1}^n E(X_i)$
    
- **常数的期望**：$E(c) = c$
    
### 2. 方差 $D(\cdot)$ 的性质（平方放大）

方差是“波动”，它比较敏感，常数提出来要变大。

- **常数平方提出去**（**最易错点**）：$D(cX) = \mathbf{c^2} D(X)$
    
    > _直观理解_：如果数据放大10倍，波动范围会放大10倍，但方差是“平方”量纲，所以波动值会放大100倍。
    
- **加法拆开**：$D(X + Y) = D(X) + D(Y)$ （**前提：X, Y 相互独立**，采样样本通常默认独立）
    
- **常数的方差**：$D(c) = 0$ （常数不波动）
    
### 3. 期望与方差的“桥梁”公式

$$D(X) = E(X^2) - [E(X)]^2$$

通常我们把它变形用来求 $E(X^2)$（二阶原点矩）：

$$E(X^2) = D(X) + [E(X)]^2$$

> _什么时候用？_ 当你看到公式里有 $\sum X_i^2$ 这种平方项求期望时，必须立刻想到这个代换。

### 4. 特殊分布

如果 $X \sim N(0, 1)$（标准正态）：

- $X^2 \sim \chi^2(1)$ （卡方分布，自由度1）
    
- $D(X^2) = 2$ 



### 1. 定理一：样本均值的分布（最基础）

内容：

**如果总体 $X \sim N(\mu, \sigma^2)$，那么样本均值 $\bar{X}$ 也服从正态分布。**

不管样本量 $n$ 是大是小，这个结论都成立。

**公式**：

$$\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$$

标准化后：

$$Z = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim N(0, 1)$$

- **考点**：题目里如果给了 $\sigma$（已知方差），让你求 $\bar{X}$ 的概率，直接用这个。
    

---

### 2. 定理二：Cochran定理推论（样本方差的分布）


内容：

样本方差 $S^2$ 经过“标准化”处理后，服从自由度为 $n-1$ 的卡方分布。

**公式（必背）**：

$$\frac{(n-1)S^2}{\sigma^2} = \frac{\sum_{i=1}^n (X_i - \bar{X})^2}{\sigma^2} \sim \chi^2(n-1)$$

**直观记忆**：

- 为什么要乘 $(n-1)$ 除以 $\sigma^2$？
    
    是为了把单位消掉，凑成标准正态平方和的形式。
    
- 为什么自由度是 $n-1$？
    
    因为公式里用的是 $\bar{X}$（估计值）而不是 $\mu$（真值），导致一个自由度被“固定”住了（受 $\sum(X_i-\bar{X})=0$ 约束）。
    
- **考点**：
    
    - 题目让你求 $S^2$ 大于某个数的概率。
        
    - 题目让你构造 $\chi^2$ 分布（如上一题的分母部分）。
        

---

### 3. 定理三：Fisher引理（独立性定理）

这是一个非常神奇且重要的性质，只在正态总体中成立！

内容：

正态总体的样本均值 $\bar{X}$ 与 样本方差 $S^2$ 是相互独立的。

**解读**：

- 这意味着：如果我们画个图，横轴是 $\bar{X}$，纵轴是 $S^2$，点是散乱分布的，没有关联。
    
- **对比**：在其他分布（比如你刚做的泊松分布）中，均值越大，方差通常也越大，它俩是不独立的。但在正态分布里，它俩互不相干。
    
- **考点**：
    
    - 构造 t 分布时，分子用 $\bar{X}$，分母用 $S$，题目如果不说它俩独立，你就没法证明它是 t 分布。这时就要引用这个定理：“由正态总体均值与方差的独立性可知……”。
        

---

### 4. 定理四：t 分布的构造（综合前三个）

这是考试中最喜欢考的**“变形金刚”**，它把前三个定理合体了。

背景：

当总体方差 $\sigma^2$ 未知时，我们没法用定理一里的 $Z$（因为没法除以 $\sigma$）。

我们需要用样本标准差 $S$ 去代替 $\sigma$。这一代替，分布就从 $N(0,1)$ 变成了 $t(n-1)$。

**公式（必背）**：

$$T = \frac{\bar{X} - \mu}{S / \sqrt{n}} \sim t(n-1)$$

**推导逻辑**：

$$T = \frac{\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S^2}{\sigma^2} \cdot \frac{1}{n-1}}} = \frac{N(0,1)}{\sqrt{\chi^2(n-1)/(n-1)}}$$

- 分子是定理一（$Z$）。
    
- 分母里包含了定理二（$\chi^2$）。
    
- 分子分母能除，是因为定理三（独立性）。
    

---

### 5. 番外篇：两个正态总体的定理（F分布）

如果你遇到两个样本（比如 $X$ 组和 $Y$ 组），还会用到这个：

内容：

两个独立正态样本方差的比值，服从 F 分布。

**公式**：

$$\frac{S_1^2 / \sigma_1^2}{S_2^2 / \sigma_2^2} \sim F(n_1-1, n_2-1)$$

特别地，如果题目假设方差相等 $\sigma_1^2 = \sigma_2^2$（通常都会这么假设），公式简化为：

$$\frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)$$

---

### 📝 总结 Cheat Sheet

|**定理名称**|**涉及统计量**|**核心公式/结论**|**典型用途**|
|---|---|---|---|
|**均值分布**|$\bar{X}$|$\bar{X} \sim N(\mu, \sigma^2/n)$|已知 $\sigma$，求均值概率|
|**Cochran推论**|$S^2$|$\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$|求方差概率、构造卡方统计量|
|**独立性**|$\bar{X}$ 与 $S^2$|**相互独立**|证明 t 分布成立的前提|
|**t 统计量**|$\bar{X}$ 和 $S$|$\frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$|**未知 $\sigma$**，检验均值|
|**F 统计量**|$S_1^2$ 和 $S_2^2$|$\frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)$|比较两个方差是否相等|

做题技巧：

看到题目里出现 $\bar{X}$ 和 $\mu$，先想正态分布。

如果题目里 $\sigma$ 没给，换成了 $S$，马上把正态分布划掉，改成 t 分布。

看到题目里出现 $S^2$ 或 $\sum(X_i-\bar{X})^2$，马上想 卡方分布。

看到两个 $S^2$ 相除，马上想 F 分布。

## 估计均值$\mu$

所有的置信区间公式长得都一样：


$$\text{区间} = \text{样本均值}(\bar{X}) \pm \text{容错半径}$$

容错半径由三个因素决定：

1. **数据的波动大小**：方差越大，网得张得越大（$S$）。
    
2. **样本量**：测得越多，越精准，网可以收得越窄（$\sqrt{n}$）。
    
3. **胆量（置信水平）**：你要求 95% 的把握，网就要大一点；如果只要求 80% 的把握，网就可以小一点（这就涉及到 $t$ 分布的系数）。

### 分布类型

这是做这类题的第一道坎。我们要在 Z 分布（标准正态）和 t 分布之间做选择。

**判据：**
> 
> - **已知** $\sigma$ $\rightarrow$ 用 **Z 分布**。
>     
> - **未知** $\sigma$（只给了样本方差 $S$） $\rightarrow$ 用 **t 分布**。

#### Z分布

$$\bar{X} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}}$$
- **$\bar{X}$（基准点）**：我就站在样本均值这里。
    
- **$\frac{\sigma}{\sqrt{n}}$（精度）**：这是“真实的精度”。因为 $\sigma$ 是真值，所以这个精度是实打实的，没有水分。
    
- **$z_{\alpha/2}$（胆量）**：这是“标准胆量”。比如 95% 置信度对应 1.96。因为精度是真实的，所以我不需要额外加保险，直接用标准系数。
#### t分布
$$\bar{X} \pm t_{\alpha/2}(n-1) \frac{S}{\sqrt{n}}$$
这里有两个关键的 **“偷梁换柱”** ，导致我们需要付出代价：

- 变化一：$\sigma \to S$（精度注水了）
    
    我们被迫用样本标准差 $S$ 去代替 $\sigma$。
    
    $S$ 是个不稳定的家伙（再抽一次样本，$S$ 就变了）。这引入了额外的噪音。
    
- 变化二：$z \to t$（胆量变小了/系数变大了）
    
    因为精度里混入了噪音（$S$），如果我们还用原来的系数 1.96，那肯定会经常出错（网不住鱼）。
    
    所以我们要用 $t$ 系数。
    
    $t$ 系数的一个特点是：它永远比 $z$ 大！
    
    - _比如_：95% 置信度，Z 是 1.96。但如果样本量 $n=16$，t 是 2.131。
        
    - **为什么要变大？** 这就是为了抵消 $S$ 带来的不稳定性。就是为了把那个区间撑得更开一点，以此来补偿我们对 $\sigma$ 的无知。
        
- 为什么有 $(n-1)$？
    
    因为我们在算 $S$ 的时候，用到了一次 $\bar{X}$，消耗了一个自由度。样本量 $n$ 越小，$t$ 分布就越“胖”（系数越大）；当 $n \to \infty$ 时，$S$ 趋近于 $\sigma$，那么 $t$ 分布就变成了 $Z$ 分布（胖子变瘦了）。


## 估计方差 $\sigma^2$

如果说估计均值是寻找“鱼群的中心”，那么估计方差就是评估“鱼群游得有多散”。

这里的情况完全变了：

1. **对象变了**：方差 $\sigma^2$ 本质是**平方和**，它永远是正数。
    
2. **形状变了**：正态分布和 t 分布都是左右对称的（钟形），但方差服从的分布是**歪的**（偏态）。
    

### 分布类型：卡方分布 ($\chi^2$)

我们不能再用 Z 或 t 了，必须召唤专管“平方和”的分布——**卡方分布**。

构造枢轴量：

$$\chi^2 = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$$

### 置信区间公式（这里有个巨大的坑）

与均值的“加减法”不同，方差的区间是**“除法”**，而且**不对称**。

$$\left[ \frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)}, \quad \frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)} \right]$$

**直观理解公式中的“反直觉”之处：**

1. **为什么是除法？**
    
    - 看上面的枢轴量公式，$\sigma^2$ 在分母上。要把 $\sigma^2$ 解出来，就需要把原本在分母的东西翻上去，把原本在等号另一边的 $\chi^2$ 除下来。
        
2. **为什么分母一大一小？（不对称性）**
    
    - 卡方分布长得像个滑梯：左边陡，右边拖着长长的尾巴。
        
    - 我们需要查两个临界值，它们离中心的距离是不一样的。
        
3. **谁做下限，谁做上限？（倒置关系）**
    
    - **下限（左边）**：你需要算出一个**小**的数。
        
        - 分子不变，分母要**大**。
            
        - 所以除以 $\chi^2_{\alpha/2}$（右尾临界值，数值很大）。
            
    - **上限（右边）**：你需要算出一个**大**的数。
        
        - 分子不变，分母要**小**。
            
        - 所以除以 $\chi^2_{1-\alpha/2}$（左尾临界值，数值很小，接近0）。
            
    
    > 记忆口诀：
    > 
    > 大的除以小的（得上限），小的除以大的（得下限）。
    

### 总结：均值 vs 方差

|**特性**|**估计均值 μ**|**估计方差 σ2**|
|---|---|---|
|**分布**|Z 分布或 t 分布（对称）|$\chi^2$ 分布（不对称）|
|**公式结构**|$\bar{X} \pm \text{半径}$ (加减法)|$[\frac{A}{\text{大数}}, \frac{A}{\text{小数}}]$ (除法)|
|**临界值**|查一个数 ($\pm$ 号搞定)|**必须查两个不同的数**|
|**自由度**|Z 无需自由度 / t 需要 $n-1$|需要 $n-1$|

## 均值

思路是构造服从t分布的统计量T，计算拒绝域，然后将题目给定的统计量带入T的公式计算出T，看是否落到拒绝域。

1. 构造t分布

$$\underbrace{T}_{\text{统计量}} = \frac{\underbrace{\bar{x} - \mu}_{\text{距离}}}{\underbrace{S/\sqrt{n}}_{\text{标准误}}}$$
跟置信区间一样，用抽样的方差代替总体标准差就构造T分布，已知总体标准差$\sigma$就构造Z分布：$$Z = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}}$$

2. 计算拒绝域

根据给定的alpha查表，得出拒绝域 $W = \{T \le -t_{\alpha}(n-1)\}$   

3. 代入题目给定的参数计算统计量T在哪里

$$T = \frac{\bar{x} - \mu_0}{S/\sqrt{n}}$$
4. 如果T落在拒绝域，则拒绝假设。

## 方差

跟均值的差不多，构造的是卡方分布：
$$K = \frac{(n-1)S^2}{\sigma^2}$$

### 置信区间和假设检验

简直就是一个东西，相同的公式，只是把不同的变量放到等号左侧。置信区间是把X放到左侧，假设检验是构造出来的t/z/卡方分布变量
